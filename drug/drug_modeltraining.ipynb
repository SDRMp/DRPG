{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "dstype = 'drug' \n",
    "mname = 'debertaV3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/bhairavi/om/om5/drug/debertaV3_drug\n"
     ]
    }
   ],
   "source": [
    " \n",
    "modelpath = 'microsoft/deberta-v3-base'\n",
    "# modelpath = \"bert-base-uncased\"\n",
    "\n",
    "\n",
    "datapath = None\n",
    "saveDIR = f\"/home/bhairavi/om/om5/{dstype}/{mname}_{dstype}\"\n",
    "print(saveDIR)\n",
    "# %%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# %%\n",
    "# %%\n",
    " \n",
    "import os\n",
    "import torch  \n",
    "\n",
    "torch.cuda.empty_cache() \n",
    "\n",
    "import pandas as pd\n",
    "from datasets import Dataset, DatasetDict, load_metric\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report\n",
    " \n",
    "\n",
    " \n",
    "\n",
    "\n",
    "# %%\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# datas = load_dataset(\"TaiChan3/drugReviews\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((161297, 7), (53766, 7))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"/home/bhairavi/om/om5/drug/train.csv\")\n",
    "test_df = pd.read_csv(\"/home/bhairavi/om/om5/drug/test.csv\")\n",
    "\n",
    "train_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['split'] = 'train'\n",
    "\n",
    "test_df['split'] = 'test'\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([train_df, test_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uniqueID</th>\n",
       "      <th>drugName</th>\n",
       "      <th>condition</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>date</th>\n",
       "      <th>usefulCount</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30080</th>\n",
       "      <td>15912</td>\n",
       "      <td>Ethinyl estradiol / norethindrone</td>\n",
       "      <td>Birth Control</td>\n",
       "      <td>\"After being on the same birth control for 2 y...</td>\n",
       "      <td>9</td>\n",
       "      <td>28-Jul-16</td>\n",
       "      <td>9</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106378</th>\n",
       "      <td>80603</td>\n",
       "      <td>Mobic</td>\n",
       "      <td>Osteoarthritis</td>\n",
       "      <td>\"Had surgery for torn meniscis and as result e...</td>\n",
       "      <td>9</td>\n",
       "      <td>8-Jun-10</td>\n",
       "      <td>50</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62374</th>\n",
       "      <td>173507</td>\n",
       "      <td>Clonazepam</td>\n",
       "      <td>Anxiety</td>\n",
       "      <td>\"I have used Clonazepam for over 10 years. Dos...</td>\n",
       "      <td>9</td>\n",
       "      <td>1-Jan-09</td>\n",
       "      <td>8</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189686</th>\n",
       "      <td>66366</td>\n",
       "      <td>Valacyclovir</td>\n",
       "      <td>Herpes Simplex, Suppression</td>\n",
       "      <td>\"The day you are diagnosed with HSV2 is an inc...</td>\n",
       "      <td>10</td>\n",
       "      <td>20-Apr-15</td>\n",
       "      <td>192</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150405</th>\n",
       "      <td>33330</td>\n",
       "      <td>Microgestin Fe 1 / 20</td>\n",
       "      <td>Birth Control</td>\n",
       "      <td>\"This pill made me so crazy and bi polar I hav...</td>\n",
       "      <td>1</td>\n",
       "      <td>3-Aug-16</td>\n",
       "      <td>6</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        uniqueID                           drugName  \\\n",
       "30080      15912  Ethinyl estradiol / norethindrone   \n",
       "106378     80603                              Mobic   \n",
       "62374     173507                         Clonazepam   \n",
       "189686     66366                       Valacyclovir   \n",
       "150405     33330              Microgestin Fe 1 / 20   \n",
       "\n",
       "                          condition  \\\n",
       "30080                 Birth Control   \n",
       "106378               Osteoarthritis   \n",
       "62374                       Anxiety   \n",
       "189686  Herpes Simplex, Suppression   \n",
       "150405                Birth Control   \n",
       "\n",
       "                                                   review  rating       date  \\\n",
       "30080   \"After being on the same birth control for 2 y...       9  28-Jul-16   \n",
       "106378  \"Had surgery for torn meniscis and as result e...       9   8-Jun-10   \n",
       "62374   \"I have used Clonazepam for over 10 years. Dos...       9   1-Jan-09   \n",
       "189686  \"The day you are diagnosed with HSV2 is an inc...      10  20-Apr-15   \n",
       "150405  \"This pill made me so crazy and bi polar I hav...       1   3-Aug-16   \n",
       "\n",
       "        usefulCount  split  \n",
       "30080             9  train  \n",
       "106378           50  train  \n",
       "62374             8  train  \n",
       "189686          192   test  \n",
       "150405            6  train  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# %%\n",
    "\n",
    "# %%\n",
    "df.sample(5)\n",
    "\n",
    "\n",
    "# %%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['uniqueID', 'drugName', 'condition', 'review', 'rating', 'date',\n",
       "       'usefulCount', 'split'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['review']\n",
    "\n",
    "df['label'] =  df['condition']\n",
    "\n",
    "\n",
    "df = df[['text', 'label', 'split']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "Birth Control                                   38436\n",
       "Depression                                      12164\n",
       "Pain                                             8245\n",
       "Anxiety                                          7812\n",
       "Acne                                             7435\n",
       "                                                ...  \n",
       "Systemic Candidiasis                                1\n",
       "Wilson's Disease                                    1\n",
       "unctional Gastric Disorde                           1\n",
       "Sepsis                                              1\n",
       "105</span> users found this comment helpful.        1\n",
       "Name: count, Length: 916, dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_counts = df['label'].value_counts()\n",
    "filtered_df = df[df['label'].map(label_counts) > threshold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "Birth Control                                                          38436\n",
       "Depression                                                             12164\n",
       "Pain                                                                    8245\n",
       "Anxiety                                                                 7812\n",
       "Acne                                                                    7435\n",
       "                                                                       ...  \n",
       "actor IX Deficiency                                                        4\n",
       "Esophageal Variceal Hemorrhage Prophylaxis                                 4\n",
       "Liver Magnetic Resonance Imaging                                           4\n",
       "Prosthetic Heart Valves, Mechanical Valves - Thrombosis Prophylaxis        4\n",
       "llicle Stimulation                                                         4\n",
       "Name: count, Length: 657, dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[54], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m le\u001b[38;5;241m.\u001b[39mfit_transform(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      6\u001b[0m fig \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m8\u001b[39m,\u001b[38;5;241m6\u001b[39m)) \n\u001b[0;32m----> 7\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlabel\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcount\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msort_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbarh\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mylim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m   \u001b[49m\u001b[43mtitle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mNUMBER OF text IN EACH label CATEGORY\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNumber of ocurrences\u001b[39m\u001b[38;5;124m'\u001b[39m, fontsize \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m);\n\u001b[1;32m     11\u001b[0m numlabel \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mnunique()\n",
      "File \u001b[0;32m~/om/lib/python3.10/site-packages/pandas/plotting/_core.py:1280\u001b[0m, in \u001b[0;36mPlotAccessor.barh\u001b[0;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[1;32m   1194\u001b[0m \u001b[38;5;129m@Appender\u001b[39m(\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m \u001b[38;5;124;03m    See Also\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1269\u001b[0m     \u001b[38;5;28mself\u001b[39m, x: Hashable \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, y: Hashable \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m   1270\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m PlotAccessor:\n\u001b[1;32m   1271\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1272\u001b[0m \u001b[38;5;124;03m    Make a horizontal bar plot.\u001b[39;00m\n\u001b[1;32m   1273\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1278\u001b[0m \u001b[38;5;124;03m    other axis represents a measured value.\u001b[39;00m\n\u001b[1;32m   1279\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1280\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkind\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbarh\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/om/lib/python3.10/site-packages/pandas/plotting/_core.py:1030\u001b[0m, in \u001b[0;36mPlotAccessor.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1027\u001b[0m             label_name \u001b[38;5;241m=\u001b[39m label_kw \u001b[38;5;129;01mor\u001b[39;00m data\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[1;32m   1028\u001b[0m             data\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m label_name\n\u001b[0;32m-> 1030\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mplot_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkind\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkind\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/om/lib/python3.10/site-packages/pandas/plotting/_matplotlib/__init__.py:71\u001b[0m, in \u001b[0;36mplot\u001b[0;34m(data, kind, **kwargs)\u001b[0m\n\u001b[1;32m     69\u001b[0m         kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124max\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(ax, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mleft_ax\u001b[39m\u001b[38;5;124m\"\u001b[39m, ax)\n\u001b[1;32m     70\u001b[0m plot_obj \u001b[38;5;241m=\u001b[39m PLOT_CLASSES[kind](data, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 71\u001b[0m \u001b[43mplot_obj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     72\u001b[0m plot_obj\u001b[38;5;241m.\u001b[39mdraw()\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m plot_obj\u001b[38;5;241m.\u001b[39mresult\n",
      "File \u001b[0;32m~/om/lib/python3.10/site-packages/pandas/plotting/_matplotlib/core.py:508\u001b[0m, in \u001b[0;36mMPLPlot.generate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    506\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ax \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes:\n\u001b[1;32m    507\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_post_plot_logic_common(ax)\n\u001b[0;32m--> 508\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post_plot_logic\u001b[49m\u001b[43m(\u001b[49m\u001b[43max\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/om/lib/python3.10/site-packages/pandas/plotting/_matplotlib/core.py:1969\u001b[0m, in \u001b[0;36mBarPlot._post_plot_logic\u001b[0;34m(self, ax, data)\u001b[0m\n\u001b[1;32m   1966\u001b[0m s_edge \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39max_pos[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m0.25\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlim_offset\n\u001b[1;32m   1967\u001b[0m e_edge \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39max_pos[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m0.25\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbar_width \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlim_offset\n\u001b[0;32m-> 1969\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_decorate_ticks\u001b[49m\u001b[43m(\u001b[49m\u001b[43max\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_index_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstr_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ms_edge\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43me_edge\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/om/lib/python3.10/site-packages/pandas/plotting/_matplotlib/core.py:2033\u001b[0m, in \u001b[0;36mBarhPlot._decorate_ticks\u001b[0;34m(self, ax, name, ticklabels, start_edge, end_edge)\u001b[0m\n\u001b[1;32m   2023\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_decorate_ticks\u001b[39m(\n\u001b[1;32m   2024\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   2025\u001b[0m     ax: Axes,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2030\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2031\u001b[0m     \u001b[38;5;66;03m# horizontal bars\u001b[39;00m\n\u001b[1;32m   2032\u001b[0m     ax\u001b[38;5;241m.\u001b[39mset_ylim((start_edge, end_edge))\n\u001b[0;32m-> 2033\u001b[0m     \u001b[43max\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_yticks\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtick_pos\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2034\u001b[0m     ax\u001b[38;5;241m.\u001b[39mset_yticklabels(ticklabels)\n\u001b[1;32m   2035\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_index:\n",
      "File \u001b[0;32m~/om/lib/python3.10/site-packages/matplotlib/axes/_base.py:74\u001b[0m, in \u001b[0;36m_axis_method_wrapper.__set_name__.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 74\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_method\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/om/lib/python3.10/site-packages/matplotlib/axis.py:2183\u001b[0m, in \u001b[0;36mAxis.set_ticks\u001b[0;34m(self, ticks, labels, minor, **kwargs)\u001b[0m\n\u001b[1;32m   2178\u001b[0m     first_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(kwargs))\n\u001b[1;32m   2179\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2180\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncorrect use of keyword argument \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfirst_key\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m. Keyword arguments \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2181\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mother than \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mminor\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m modify the text labels and can only be used if \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2182\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m are passed as well.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 2183\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_tick_locations\u001b[49m\u001b[43m(\u001b[49m\u001b[43mticks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mminor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mminor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2184\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2185\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_ticklabels(labels, minor\u001b[38;5;241m=\u001b[39mminor, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/om/lib/python3.10/site-packages/matplotlib/axis.py:2135\u001b[0m, in \u001b[0;36mAxis._set_tick_locations\u001b[0;34m(self, ticks, minor)\u001b[0m\n\u001b[1;32m   2133\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2134\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_major_locator(locator)\n\u001b[0;32m-> 2135\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_major_ticks\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mticks\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/om/lib/python3.10/site-packages/matplotlib/axis.py:1672\u001b[0m, in \u001b[0;36mAxis.get_major_ticks\u001b[0;34m(self, numticks)\u001b[0m\n\u001b[1;32m   1670\u001b[0m     tick \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_tick(major\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   1671\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmajorTicks\u001b[38;5;241m.\u001b[39mappend(tick)\n\u001b[0;32m-> 1672\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_copy_tick_props\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmajorTicks\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtick\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1674\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmajorTicks[:numticks]\n",
      "File \u001b[0;32m~/om/lib/python3.10/site-packages/matplotlib/axis.py:1618\u001b[0m, in \u001b[0;36mAxis._copy_tick_props\u001b[0;34m(self, src, dest)\u001b[0m\n\u001b[1;32m   1616\u001b[0m dest\u001b[38;5;241m.\u001b[39mlabel1\u001b[38;5;241m.\u001b[39mupdate_from(src\u001b[38;5;241m.\u001b[39mlabel1)\n\u001b[1;32m   1617\u001b[0m dest\u001b[38;5;241m.\u001b[39mlabel2\u001b[38;5;241m.\u001b[39mupdate_from(src\u001b[38;5;241m.\u001b[39mlabel2)\n\u001b[0;32m-> 1618\u001b[0m \u001b[43mdest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtick1line\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate_from\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtick1line\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1619\u001b[0m dest\u001b[38;5;241m.\u001b[39mtick2line\u001b[38;5;241m.\u001b[39mupdate_from(src\u001b[38;5;241m.\u001b[39mtick2line)\n\u001b[1;32m   1620\u001b[0m dest\u001b[38;5;241m.\u001b[39mgridline\u001b[38;5;241m.\u001b[39mupdate_from(src\u001b[38;5;241m.\u001b[39mgridline)\n",
      "File \u001b[0;32m~/om/lib/python3.10/site-packages/matplotlib/lines.py:1357\u001b[0m, in \u001b[0;36mLine2D.update_from\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m   1354\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_solidjoinstyle \u001b[38;5;241m=\u001b[39m other\u001b[38;5;241m.\u001b[39m_solidjoinstyle\n\u001b[1;32m   1356\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_linestyle \u001b[38;5;241m=\u001b[39m other\u001b[38;5;241m.\u001b[39m_linestyle\n\u001b[0;32m-> 1357\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_marker \u001b[38;5;241m=\u001b[39m \u001b[43mMarkerStyle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmarker\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mother\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_marker\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1358\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_drawstyle \u001b[38;5;241m=\u001b[39m other\u001b[38;5;241m.\u001b[39m_drawstyle\n",
      "File \u001b[0;32m~/om/lib/python3.10/site-packages/matplotlib/markers.py:248\u001b[0m, in \u001b[0;36mMarkerStyle.__init__\u001b[0;34m(self, marker, fillstyle, transform, capstyle, joinstyle)\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_user_joinstyle \u001b[38;5;241m=\u001b[39m JoinStyle(joinstyle) \u001b[38;5;28;01mif\u001b[39;00m joinstyle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_fillstyle(fillstyle)\n\u001b[0;32m--> 248\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_marker\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmarker\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/om/lib/python3.10/site-packages/matplotlib/markers.py:323\u001b[0m, in \u001b[0;36mMarkerStyle._set_marker\u001b[0;34m(self, marker)\u001b[0m\n\u001b[1;32m    321\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_marker_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_tuple_marker\n\u001b[1;32m    322\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(marker, MarkerStyle):\n\u001b[0;32m--> 323\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mcopy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmarker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__dict__\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    324\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    325\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/lib/python3.10/copy.py:146\u001b[0m, in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    144\u001b[0m copier \u001b[38;5;241m=\u001b[39m _deepcopy_dispatch\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mcls\u001b[39m)\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copier \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 146\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcopier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    148\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;28mtype\u001b[39m):\n",
      "File \u001b[0;32m/usr/lib/python3.10/copy.py:231\u001b[0m, in \u001b[0;36m_deepcopy_dict\u001b[0;34m(x, memo, deepcopy)\u001b[0m\n\u001b[1;32m    229\u001b[0m memo[\u001b[38;5;28mid\u001b[39m(x)] \u001b[38;5;241m=\u001b[39m y\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m x\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m--> 231\u001b[0m     y[deepcopy(key, memo)] \u001b[38;5;241m=\u001b[39m \u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
      "File \u001b[0;32m/usr/lib/python3.10/copy.py:153\u001b[0m, in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    151\u001b[0m copier \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__deepcopy__\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copier \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 153\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcopier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m     reductor \u001b[38;5;241m=\u001b[39m dispatch_table\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mcls\u001b[39m)\n",
      "File \u001b[0;32m~/om/lib/python3.10/site-packages/matplotlib/path.py:285\u001b[0m, in \u001b[0;36mPath.__deepcopy__\u001b[0;34m(self, memo)\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;124;03mReturn a deepcopy of the `Path`.  The `Path` will not be\u001b[39;00m\n\u001b[1;32m    282\u001b[0m \u001b[38;5;124;03mreadonly, even if the source `Path` is.\u001b[39;00m\n\u001b[1;32m    283\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;66;03m# Deepcopying arrays (vertices, codes) strips the writeable=False flag.\u001b[39;00m\n\u001b[0;32m--> 285\u001b[0m p \u001b[38;5;241m=\u001b[39m \u001b[43mcopy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    286\u001b[0m p\u001b[38;5;241m.\u001b[39m_readonly \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m p\n",
      "File \u001b[0;32m/usr/lib/python3.10/copy.py:161\u001b[0m, in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    159\u001b[0m reductor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__reduce_ex__\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m reductor \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 161\u001b[0m     rv \u001b[38;5;241m=\u001b[39m \u001b[43mreductor\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    163\u001b[0m     reductor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__reduce__\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    " \n",
    "le = LabelEncoder()\n",
    "df['target'] = le.fit_transform(df['label'])\n",
    " \n",
    "fig = plt.figure(figsize=(8,6)) \n",
    "df.groupby('label').text.count().sort_values().plot.barh(\n",
    "    ylim=0,   title= 'NUMBER OF text IN EACH label CATEGORY\\n')\n",
    "plt.xlabel('Number of ocurrences', fontsize = 10);\n",
    " \n",
    "numlabel = df['target'].nunique()\n",
    "numlabel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['text', 'label', 'split', 'target'], dtype='object')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "Birth Control                                                          38436\n",
      "Depression                                                             12164\n",
      "Pain                                                                    8245\n",
      "Anxiety                                                                 7812\n",
      "Acne                                                                    7435\n",
      "                                                                       ...  \n",
      "actor IX Deficiency                                                        4\n",
      "Esophageal Variceal Hemorrhage Prophylaxis                                 4\n",
      "Liver Magnetic Resonance Imaging                                           4\n",
      "Prosthetic Heart Valves, Mechanical Valves - Thrombosis Prophylaxis        4\n",
      "llicle Stimulation                                                         4\n",
      "Name: count, Length: 657, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "label_counts = df['label'].value_counts()\n",
    "print(label_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Birth Control', 'Depression', 'Pain', 'Anxiety', 'Acne',\n",
      "       'Bipolar Disorde', 'Insomnia', 'Weight Loss', 'Obesity', 'ADHD',\n",
      "       ...\n",
      "       'Hypertriglyceridemia',\n",
      "       'Vitamin/Mineral Supplementation during Pregnancy/Lactation',\n",
      "       'Sexual Dysfunction, SSRI Induced', 'Psychosis', 'Menorrhagia',\n",
      "       'Hypersomnia', 'Nausea/Vomiting, Chemotherapy Induced',\n",
      "       'Conjunctivitis, Allergic', 'Stomach Ulce', 'Barrett's Esophagus'],\n",
      "      dtype='object', name='label', length=200)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# top_100_labels = label_counts.index[:200]\n",
    "# print(top_100_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the DataFrame to retain only rows where 'condition' is in the top 100 frequent labels\n",
    "# df_filtered = df[df['label'].isin(top_100_labels)]\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>split</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"My son is halfway through his fourth week of ...</td>\n",
       "      <td>ADHD</td>\n",
       "      <td>train</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"I used to take another oral contraceptive, wh...</td>\n",
       "      <td>Birth Control</td>\n",
       "      <td>train</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"This is my first time using any form of birth...</td>\n",
       "      <td>Birth Control</td>\n",
       "      <td>train</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"Suboxone has completely turned my life around...</td>\n",
       "      <td>Opiate Dependence</td>\n",
       "      <td>train</td>\n",
       "      <td>218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>\"2nd day on 5mg started to work with rock hard...</td>\n",
       "      <td>Benign Prostatic Hyperplasia</td>\n",
       "      <td>train</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215057</th>\n",
       "      <td>\"I started taking Apri about 7 months ago. My ...</td>\n",
       "      <td>Birth Control</td>\n",
       "      <td>test</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215059</th>\n",
       "      <td>\"I&amp;#039;ve been taking Lexapro (escitaploprgra...</td>\n",
       "      <td>Anxiety</td>\n",
       "      <td>test</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215060</th>\n",
       "      <td>\"I&amp;#039;m married, 34 years old and I have no ...</td>\n",
       "      <td>Birth Control</td>\n",
       "      <td>test</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215061</th>\n",
       "      <td>\"I was prescribed Nucynta for severe neck/shou...</td>\n",
       "      <td>Pain</td>\n",
       "      <td>test</td>\n",
       "      <td>229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215062</th>\n",
       "      <td>\"It works!!!\"</td>\n",
       "      <td>Sciatica</td>\n",
       "      <td>test</td>\n",
       "      <td>275</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>203441 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  \\\n",
       "1       \"My son is halfway through his fourth week of ...   \n",
       "2       \"I used to take another oral contraceptive, wh...   \n",
       "3       \"This is my first time using any form of birth...   \n",
       "4       \"Suboxone has completely turned my life around...   \n",
       "5       \"2nd day on 5mg started to work with rock hard...   \n",
       "...                                                   ...   \n",
       "215057  \"I started taking Apri about 7 months ago. My ...   \n",
       "215059  \"I&#039;ve been taking Lexapro (escitaploprgra...   \n",
       "215060  \"I&#039;m married, 34 years old and I have no ...   \n",
       "215061  \"I was prescribed Nucynta for severe neck/shou...   \n",
       "215062                                      \"It works!!!\"   \n",
       "\n",
       "                               label  split  target  \n",
       "1                               ADHD  train      13  \n",
       "2                      Birth Control  train      57  \n",
       "3                      Birth Control  train      57  \n",
       "4                  Opiate Dependence  train     218  \n",
       "5       Benign Prostatic Hyperplasia  train      54  \n",
       "...                              ...    ...     ...  \n",
       "215057                 Birth Control   test      57  \n",
       "215059                       Anxiety   test      35  \n",
       "215060                 Birth Control   test      57  \n",
       "215061                          Pain   test     229  \n",
       "215062                      Sciatica   test     275  \n",
       "\n",
       "[203441 rows x 4 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "657"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numlabel = df['target'].nunique()\n",
    "numlabel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bhairavi/om/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "/home/bhairavi/om/lib/python3.10/site-packages/transformers/convert_slow_tokenizer.py:551: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DebertaV2ForSequenceClassification(\n",
       "  (deberta): DebertaV2Model(\n",
       "    (embeddings): DebertaV2Embeddings(\n",
       "      (word_embeddings): Embedding(128100, 768, padding_idx=0)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "      (dropout): StableDropout()\n",
       "    )\n",
       "    (encoder): DebertaV2Encoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (rel_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (pooler): ContextPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): StableDropout()\n",
       "  )\n",
       "  (classifier): Linear(in_features=768, out_features=336, bias=True)\n",
       "  (dropout): StableDropout()\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "device = \"cuda\"  # the device to load the model onto\n",
    "\n",
    "# Load the tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(modelpath)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(modelpath, num_labels=numlabel)\n",
    "\n",
    "# Move the model to the specified device\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['token_length'] = df['text'].apply(lambda x: len(tokenizer.tokenize(x)))\n",
    "\n",
    "# # Calculate the maximum token length\n",
    "# max_length = df['token_length'].max()\n",
    "\n",
    "# # Calculate the next maximum token length\n",
    "# next_max_token_length = df['token_length'].nlargest(2).iloc[1]\n",
    "\n",
    "# # Calculate the average token length\n",
    "# average_token_length = df['token_length'].mean()\n",
    "\n",
    "# # Display the results\n",
    "# print(f\"Maximum token length: {max_length}\")\n",
    "# print(f\"Next maximum token length: {next_max_token_length}\")\n",
    "# print(f\"Average token length: {average_token_length:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = df[df['split'] == 'train'].drop(columns=['split'])\n",
    "\n",
    "test_df = df[df['split'] == 'test'].drop(columns=['split'])\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|| 169634/169634 [01:07<00:00, 2496.13 examples/s]\n",
      "Map: 100%|| 29936/29936 [00:12<00:00, 2460.32 examples/s]\n",
      "Map: 100%|| 10504/10504 [00:04<00:00, 2482.00 examples/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# %%\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "# Splitting off the test set with 5% of the data\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.05, random_state=42)  # 5% for test\n",
    "for train_val_idx, test_idx in sss.split(df, df['target']):\n",
    "    train_val_df = df.iloc[train_val_idx]\n",
    "    test_df = df.iloc[test_idx]\n",
    "\n",
    "# Further split train_val_df into train and validation sets with validation set being 15.79% of the remaining data\n",
    "# (which is equivalent to 15% of the original dataset size)\n",
    "sss_val = StratifiedShuffleSplit(n_splits=1, test_size=0.15, random_state=42)  # ~15.79% of remaining data\n",
    "for train_idx, val_idx in sss_val.split(train_val_df, train_val_df['target']):\n",
    "    train_df = train_val_df.iloc[train_idx]\n",
    "    val_df = train_val_df.iloc[val_idx]\n",
    " \n",
    "\n",
    "def tokenize_and_format(examples):\n",
    "    # Tokenize the texts\n",
    "    tokenized_inputs = tokenizer(examples['text'], padding=\"max_length\", truncation=True, max_length=max_length)\n",
    "    tokenized_inputs['label'] = list(map(int, examples['target']))\n",
    "    return tokenized_inputs\n",
    "\n",
    "# Convert pandas DataFrame to Hugging Face's Dataset\n",
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "eval_dataset = Dataset.from_pandas(val_df) \n",
    "test_dataset = Dataset.from_pandas(test_df)\n",
    "\n",
    "# Map the tokenization function across the datasets\n",
    "train_dataset = train_dataset.map(tokenize_and_format, batched=True,batch_size=16)\n",
    "eval_dataset = eval_dataset.map(tokenize_and_format, batched=True,batch_size=16) \n",
    "test_dataset = test_dataset.map(tokenize_and_format, batched=True,batch_size=16)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bhairavi/om/lib/python3.10/site-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of  Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='61' max='63615' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [   61/63615 00:40 < 12:09:08, 1.45 it/s, Epoch 0.00/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 53\u001b[0m\n\u001b[1;32m     43\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m     44\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     45\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args ,  \u001b[38;5;66;03m# Here you will need to make sure that the Trainer is set up correctly\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     49\u001b[0m     tokenizer\u001b[38;5;241m=\u001b[39mtokenizer\n\u001b[1;32m     50\u001b[0m )\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m# Start training\u001b[39;00m\n\u001b[0;32m---> 53\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/om/lib/python3.10/site-packages/transformers/trainer.py:1948\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1946\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1947\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1948\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1949\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1950\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1951\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1952\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1953\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/om/lib/python3.10/site-packages/transformers/trainer.py:2289\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2286\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_begin(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[1;32m   2288\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39maccumulate(model):\n\u001b[0;32m-> 2289\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2291\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2292\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2293\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[1;32m   2294\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   2295\u001b[0m ):\n\u001b[1;32m   2296\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2297\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m~/om/lib/python3.10/site-packages/transformers/trainer.py:3328\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   3325\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_mb\u001b[38;5;241m.\u001b[39mreduce_mean()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m   3327\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss_context_manager():\n\u001b[0;32m-> 3328\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3330\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m inputs\n\u001b[1;32m   3331\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   3332\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mtorch_empty_cache_steps \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   3333\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mtorch_empty_cache_steps \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m   3334\u001b[0m ):\n",
      "File \u001b[0;32m~/om/lib/python3.10/site-packages/transformers/trainer.py:3373\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m   3371\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3372\u001b[0m     labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 3373\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3374\u001b[0m \u001b[38;5;66;03m# Save past state if it exists\u001b[39;00m\n\u001b[1;32m   3375\u001b[0m \u001b[38;5;66;03m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[1;32m   3376\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mpast_index \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/om/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/om/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/om/lib/python3.10/site-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:1322\u001b[0m, in \u001b[0;36mDebertaV2ForSequenceClassification.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1320\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss_fn(logits, labels\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m   1321\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m labels\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m labels\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m-> 1322\u001b[0m     label_index \u001b[38;5;241m=\u001b[39m \u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnonzero\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1323\u001b[0m     labels \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mlong()\n\u001b[1;32m   1324\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m label_index\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# %%\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    f1 = f1_score(labels, preds, average='weighted')\n",
    "    precision = precision_score(labels, preds, average='weighted')\n",
    "    recall = recall_score(labels, preds, average='weighted')\n",
    "    return {\n",
    "        'eval_f1': f1,\n",
    "        'eval_precision': precision,\n",
    "        'eval_recall': recall,\n",
    "    }\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "# %%\n",
    "\n",
    "# %%\n",
    " \n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",  # Use 'epoch' to evaluate at the end of each epoch\n",
    "    save_strategy=\"epoch\",  # Also use 'epoch' to save at the end of each epoch\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,  # Load the best model at the end of training based on metric\n",
    "    metric_for_best_model='f1',  # Define the metric for evaluating the best model\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    "    report_to=[] \n",
    ")\n",
    "\n",
    "\n",
    " \n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args ,  # Here you will need to make sure that the Trainer is set up correctly\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "# Start training\n",
    "trainer.train()\n",
    "\n",
    " \n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/home/bhairavi/om/om5/s2d/debertaV3_s2d/tokenizer_config.json',\n",
       " '/home/bhairavi/om/om5/s2d/debertaV3_s2d/special_tokens_map.json',\n",
       " '/home/bhairavi/om/om5/s2d/debertaV3_s2d/spm.model',\n",
       " '/home/bhairavi/om/om5/s2d/debertaV3_s2d/added_tokens.json',\n",
       " '/home/bhairavi/om/om5/s2d/debertaV3_s2d/tokenizer.json')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_directory = saveDIR\n",
    " \n",
    "\n",
    "# Save the model\n",
    "model.save_pretrained(save_directory)\n",
    "\n",
    "# Save the tokenizer (optional, but recommended)\n",
    "tokenizer.save_pretrained(save_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m keywords class evaluation detection RESULTS\n",
      "                                 precision    recall  f1-score   support\n",
      "\n",
      "                      Psoriasis     1.0000    1.0000    1.0000         7\n",
      "                 Varicose Veins     1.0000    1.0000    1.0000         7\n",
      "                        Typhoid     1.0000    0.8750    0.9333         8\n",
      "                    Chicken pox     1.0000    1.0000    1.0000         7\n",
      "                       Impetigo     0.8750    1.0000    0.9333         7\n",
      "                         Dengue     0.7000    1.0000    0.8235         7\n",
      "               Fungal infection     1.0000    0.7143    0.8333         7\n",
      "                    Common Cold     1.0000    1.0000    1.0000         7\n",
      "                      Pneumonia     1.0000    1.0000    1.0000         7\n",
      "          Dimorphic Hemorrhoids     0.8750    1.0000    0.9333         7\n",
      "                      Arthritis     1.0000    1.0000    1.0000         7\n",
      "                           Acne     1.0000    1.0000    1.0000         7\n",
      "               Bronchial Asthma     1.0000    1.0000    1.0000         8\n",
      "                   Hypertension     1.0000    0.8571    0.9231         7\n",
      "                       Migraine     1.0000    0.8571    0.9231         7\n",
      "           Cervical spondylosis     1.0000    1.0000    1.0000         7\n",
      "                       Jaundice     0.8750    1.0000    0.9333         7\n",
      "                        Malaria     1.0000    1.0000    1.0000         7\n",
      "        urinary tract infection     0.7500    0.8571    0.8000         7\n",
      "                        allergy     1.0000    0.8571    0.9231         7\n",
      "gastroesophageal reflux disease     0.8333    0.7143    0.7692         7\n",
      "                  drug reaction     0.6667    1.0000    0.8000         8\n",
      "           peptic ulcer disease     1.0000    0.4286    0.6000         7\n",
      "                       diabetes     1.0000    1.0000    1.0000         7\n",
      "\n",
      "                       accuracy                         0.9240       171\n",
      "                      macro avg     0.9406    0.9234    0.9220       171\n",
      "                   weighted avg     0.9397    0.9240    0.9218       171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# %%\n",
    "from colorama import Fore, Style\n",
    "\n",
    "\n",
    "# %% [markdown]\n",
    "# eval dataset performance so that keywords_classes can be fixed\n",
    "\n",
    "# %%\n",
    "results = trainer.evaluate()\n",
    "\n",
    "# Predict using the trained model to get labels and predictions\n",
    "predictions, labels, _ = trainer.predict(eval_dataset)\n",
    "predictions = np.argmax(predictions, axis=1)\n",
    "\n",
    "\n",
    "# %%\n",
    "from sklearn.metrics import classification_report\n",
    "# Generate the classification report\n",
    "report = classification_report(\n",
    "    labels,\n",
    "    predictions,\n",
    "    target_names=df['label'].unique() , # Adjust this line as per your dataset\n",
    "    digits=4\n",
    ")\n",
    "print(Fore.CYAN,\"keywords class evaluation detection RESULTS\")\n",
    "print(report)\n",
    "\n",
    "\n",
    "# %% [markdown]\n",
    "# skyline\n",
    "\n",
    "# %%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mTEST DATA IS OUR SKYLINE RESULT\n",
      "                                 precision    recall  f1-score   support\n",
      "\n",
      "                      Psoriasis     1.0000    1.0000    1.0000         2\n",
      "                 Varicose Veins     1.0000    1.0000    1.0000         2\n",
      "                        Typhoid     1.0000    1.0000    1.0000         2\n",
      "                    Chicken pox     1.0000    1.0000    1.0000         3\n",
      "                       Impetigo     1.0000    1.0000    1.0000         3\n",
      "                         Dengue     1.0000    1.0000    1.0000         2\n",
      "               Fungal infection     1.0000    1.0000    1.0000         3\n",
      "                    Common Cold     1.0000    1.0000    1.0000         3\n",
      "                      Pneumonia     1.0000    1.0000    1.0000         2\n",
      "          Dimorphic Hemorrhoids     1.0000    1.0000    1.0000         2\n",
      "                      Arthritis     1.0000    1.0000    1.0000         3\n",
      "                           Acne     1.0000    1.0000    1.0000         2\n",
      "               Bronchial Asthma     1.0000    1.0000    1.0000         2\n",
      "                   Hypertension     1.0000    1.0000    1.0000         2\n",
      "                       Migraine     1.0000    1.0000    1.0000         3\n",
      "           Cervical spondylosis     1.0000    1.0000    1.0000         3\n",
      "                       Jaundice     1.0000    1.0000    1.0000         2\n",
      "                        Malaria     1.0000    1.0000    1.0000         3\n",
      "        urinary tract infection     1.0000    1.0000    1.0000         2\n",
      "                        allergy     1.0000    0.6667    0.8000         3\n",
      "gastroesophageal reflux disease     1.0000    1.0000    1.0000         3\n",
      "                  drug reaction     1.0000    1.0000    1.0000         2\n",
      "           peptic ulcer disease     1.0000    1.0000    1.0000         3\n",
      "                       diabetes     0.7500    1.0000    0.8571         3\n",
      "\n",
      "                       accuracy                         0.9833        60\n",
      "                      macro avg     0.9896    0.9861    0.9857        60\n",
      "                   weighted avg     0.9875    0.9833    0.9829        60\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# %%\n",
    "print(Fore.RED +\"TEST DATA IS OUR SKYLINE RESULT\")\n",
    " \n",
    "results = trainer.evaluate()\n",
    "\n",
    "# Predict using the trained model to get labels and predictions\n",
    "predictions, labels, _ = trainer.predict(test_dataset)\n",
    "predictions = np.argmax(predictions, axis=1)\n",
    "\n",
    "\n",
    "# %%\n",
    "from sklearn.metrics import classification_report\n",
    "# Generate the classification report\n",
    "report = classification_report(\n",
    "    labels,\n",
    "    predictions,\n",
    "    target_names=df['label'].unique() , # Adjust this line as per your dataset\n",
    "    digits=4\n",
    ")\n",
    "\n",
    "print(report)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "om",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
